{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 7, "column": 0}, "map": {"version":3,"file":"state.js","sourceRoot":"","sources":["file:///project/sandbox/user-workspace/node_modules/%40tensorflow/tfjs-layers/dist/backend/state.js/__/__/__/__/__/__/tfjs-layers/src/backend/state.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * Utilities related to persistent state in the backend.\n */\n\n/**\n * An ID to track `tf.SymbolicTensor`s and derived classes.\n * Required in different places in engine/topology.ts to identify unique\n * tensors.\n */\nlet _nextUniqueTensorId = 0;\n\nexport function getNextUniqueTensorId(): number {\n  return _nextUniqueTensorId++;\n}\n\nconst _uidPrefixes: {[prefix: string]: number} = {};\n\n/**\n * Provides a unique UID given a string prefix.\n *\n * @param prefix\n */\nexport function getUid(prefix = ''): string {\n  if (!(prefix in _uidPrefixes)) {\n    _uidPrefixes[prefix] = 0;\n  }\n  _uidPrefixes[prefix] += 1;\n  return prefix + _uidPrefixes[prefix].toString();\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;GAQG,CAEH;;GAEG,CAEH;;;;GAIG;;;;AACH,IAAI,mBAAmB,GAAG,CAAC,CAAC;AAEtB,SAAU,qBAAqB;IACnC,OAAO,mBAAmB,EAAE,CAAC;AAC/B,CAAC;AAED,MAAM,YAAY,GAA+B,CAAA,CAAE,CAAC;AAO9C,SAAU,MAAM,CAAC,MAAM,GAAG,EAAE;IAChC,IAAI,CAAC,CAAC,MAAM,IAAI,YAAY,CAAC,EAAE;QAC7B,YAAY,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC;KAC1B;IACD,YAAY,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC;IAC1B,OAAO,MAAM,GAAG,YAAY,CAAC,MAAM,CAAC,CAAC,QAAQ,EAAE,CAAC;AAClD,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 43, "column": 0}, "map": {"version":3,"file":"common.js","sourceRoot":"","sources":["file:///project/sandbox/user-workspace/node_modules/%40tensorflow/tfjs-layers/dist/backend/common.js/__/__/__/__/__/__/tfjs-layers/src/backend/common.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\nimport {backend} from '@tensorflow/tfjs-core';\nimport {DataFormat} from '../keras_format/common';\n\nlet _epsilon: number;\n\n/**\n * Returns the value of the fuzz factor used in numeric expressions.\n */\nexport function epsilon() {\n  if (_epsilon == null) {\n    _epsilon = backend().epsilon();\n  }\n  return _epsilon;\n}\n\n/**\n * Sets the value of the fuzz factor used in numeric expressions.\n * @param e New value of epsilon.\n */\nexport function setEpsilon(e: number) {\n  _epsilon = e;\n}\n\n/**\n * Returns the default image data format convention.\n */\nexport function imageDataFormat(): DataFormat {\n  return 'channelsLast';\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;GAQG;;;;;;AAEH,OAAO,EAAC,OAAO,EAAC,MAAM,uBAAuB,CAAC;;AAG9C,IAAI,QAAgB,CAAC;AAKf,SAAU,OAAO;IACrB,IAAI,QAAQ,IAAI,IAAI,EAAE;QACpB,QAAQ,0KAAG,UAAA,AAAO,EAAE,EAAC,OAAO,EAAE,CAAC;KAChC;IACD,OAAO,QAAQ,CAAC;AAClB,CAAC;AAMK,SAAU,UAAU,CAAC,CAAS;IAClC,QAAQ,GAAG,CAAC,CAAC;AACf,CAAC;AAKK,SAAU,eAAe;IAC7B,OAAO,cAAc,CAAC;AACxB,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 78, "column": 0}, "map": {"version":3,"file":"tfjs_backend.js","sourceRoot":"","sources":["file:///project/sandbox/user-workspace/node_modules/%40tensorflow/tfjs-layers/dist/backend/tfjs_backend.js/__/__/__/__/__/__/tfjs-layers/src/backend/tfjs_backend.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * deeplearn.js backend.\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {onesLike as coreOnesLike, scalar, Tensor, Tensor1D, tensor1d, Tensor2D, Tensor3D, Tensor4D, Tensor5D, tidy, where, zerosLike as coreZerosLike} from '@tensorflow/tfjs-core';\nimport {checkDataFormat} from '../common';\nimport {NotImplementedError, ValueError} from '../errors';\nimport {DataFormat, Shape} from '../keras_format/common';\nimport {HasShape} from '../types';\nimport * as math_utils from '../utils/math_utils';\n\nimport {imageDataFormat} from './common';\n\n// tslint:enable\n\n/* Setting and getting backend from deeplearn.js. */\n\n// Default deeplearn.js backend is WebGL (GPU).\nlet backend: 'cpu'|'webgl' = 'webgl';\n\nexport function setBackend(requestedBackend: 'cpu'|'webgl') {\n  tfc.setBackend(requestedBackend);\n  backend = requestedBackend;\n}\n\nexport function getBackend(): 'cpu'|'webgl' {\n  return backend;\n}\n\n/**\n * Indicates whether the backend is operating symbolically.\n *\n * This function will be used to determine how to interpret user code. If\n * it returns true, calls to the backend construct a symbolic graph; if\n * it returns false, calls to the backend execute immediately.\n */\nexport function isBackendSymbolic(): boolean {\n  return false;\n}\n\n/**\n * Get the number of elements in a Tensor.\n * @param x The Tensor.\n * @return Number of elements in `x`.\n */\nexport function countParams(x: HasShape): number {\n  const shape = x.shape;\n  if (shape.length > 0) {\n    return shape.reduce((a: number, b: number) => a * b);\n  } else {\n    // Scalar.\n    return 1;\n  }\n}\n\n/**\n * Casts a tensor to a different dtype and returns it.\n * @param x Input tensor.\n * @param dtype String: 'float32'|'int32'|'bool'.\n * @returns Tensor of the specified `dtype`.\n */\nexport function cast(x: Tensor, dtype: tfc.DataType): Tensor {\n  return tfc.cast(x, dtype);\n}\n\n/**\n * Adds a 1-sized dimension at index \"axis\".\n * @param x Input tensor.\n * @param axis Position where to add the new axis.\n * @returns Result of the dimension expansion.\n */\nexport function expandDims(x: Tensor, axis = -1): Tensor {\n  const outShape = x.shape.slice();\n  if (axis < 0) {\n    axis = outShape.length + axis + 1;\n  }\n  outShape.splice(axis, 0, 1);\n  return tfc.reshape(x, outShape);\n}\n\n/**\n * Repeats a 2D tensor.\n *\n * If `x` has shape `[samples, dim]` and `n` is 2, for example, the output\n * will have shape `[samples, 2, dim]`.\n *\n * @param x Input tensor.\n * @param n Integer, number of times to repeat.\n * @returns The result of the repeat operation.\n * @throws ValueError: If input tensor is not 2D.\n */\nexport function repeat(x: Tensor, n: number): Tensor {\n  return tidy(() => {\n    if (x.shape.length !== 2) {\n      throw new ValueError(\n          `repeat() expects a rank-2 tensor, but received a ` +\n          `rank-${x.shape.length} tensor.`);\n    }\n    const y = expandDims(x, 1);\n    return tile(y, [1, n, 1]);\n  });\n}\n\n/**\n * Flatten a Tensor into 1D.\n * @param x Input tensor.\n * @return The result of the flattening `x`.\n */\nexport function flatten(x: Tensor): Tensor {\n  const newShape = [math_utils.arrayProd(x.shape)];\n  return tfc.reshape(x, newShape);\n}\n\n/**\n * Turn a nD tensor into a 2D tensor with same 0th dimension.\n * In other words, it flattens each data samples of a batch.\n *\n * @param x The tensor to flatten. The rank of this tensor is required to be 2\n *   or higher.\n * @return The result of the flattening.\n */\nexport function batchFlatten(x: Tensor): Tensor {\n  if (x.rank <= 1) {\n    throw new ValueError(\n        `batchFlatten requires a minimum rank of 2. Got rank: ${x.rank}.`);\n  }\n  const newShape = [x.shape[0], math_utils.arrayProd(x.shape, 1)];\n  return tfc.reshape(x, newShape);\n}\n\n/**\n * Do slicing along the first axis.\n * @param array input `tf.Tensor`.\n * @param start starting index, inclusive.\n * @param size size of the slice along the first axis.\n * @returns result of the slicing.\n * @throws ValueError: If `array` is of an unsupported subtype of `tf.Tensor`.\n */\nexport function sliceAlongFirstAxis(\n    array: Tensor, start: number, size: number): Tensor {\n  return tidy(() => {\n    switch (array.rank) {\n      case 1:\n        return tfc.slice1d(array as Tensor1D, start, size);\n      case 2:\n        return tfc.slice2d(\n            array as Tensor2D, [start, 0], [size, array.shape[1]]);\n      case 3:\n        return tfc.slice3d(\n            array as Tensor3D, [start, 0, 0],\n            [size, array.shape[1], array.shape[2]]);\n      case 4:\n        return tfc.slice4d(\n            array as Tensor4D, [start, 0, 0, 0],\n            [size, array.shape[1], array.shape[2], array.shape[3]]);\n      case 5:\n        return tfc.slice(array as Tensor5D, [start, 0, 0, 0, 0], [\n          size, array.shape[1], array.shape[2], array.shape[3], array.shape[4]\n        ]);\n      case 6:\n        return tfc.slice(array, [start, 0, 0, 0, 0, 0], [\n          size, array.shape[1], array.shape[2], array.shape[3], array.shape[4],\n          array.shape[5]\n        ]);\n      default:\n        throw new ValueError(\n            `sliceAlongFirstAxis() received an unsupported tensor rank: ` +\n            `${array.rank}`);\n    }\n  });\n}\n\n/**\n * Do slicing along the last axis.\n * @param array input `tf.Tensor`.\n * @param start starting index, inclusive.\n * @param size size of the slice along the last axis.\n * @returns result of the slicing.\n * @throws ValueError: If `array` is of an unsupported subtype of `tf.Tensor`.\n */\nexport function sliceAlongLastAxis(\n    array: Tensor, start: number, size: number): Tensor {\n  return tidy(() => {\n    switch (array.rank) {\n      case 1:\n        return tfc.slice1d(array as Tensor1D, start, size);\n      case 2:\n        return tfc.slice2d(\n            array as Tensor2D, [0, start], [array.shape[0], size]);\n      case 3:\n        return tfc.slice3d(\n            array as Tensor3D, [0, 0, start],\n            [array.shape[0], array.shape[1], size]);\n      case 4:\n        return tfc.slice4d(\n            array as Tensor4D, [0, 0, 0, start],\n            [array.shape[0], array.shape[1], array.shape[2], size]);\n      default:\n        throw new ValueError(\n            `sliceAlongLastAxis() received an unsupported tensor rank: ` +\n            `${array.rank}`);\n    }\n  });\n}\n\n/**\n * Do slicing along the sepcified axis.\n * @param array input `tf.Tensor`.\n * @param start starting index, inclusive.\n * @param size of the slice along the chosen axis.\n * @param choose an axis.\n * @returns result of the slicing.\n * @throws ValueError: If `array` is of an unsupported subtype of `tf.Tensor`.\n */\nexport function sliceAlongAxis(\n    array: Tensor, start: number, size: number, axis: number): Tensor {\n  return tidy(() => {\n    switch (array.rank) {\n      case 1:\n        return tfc.slice1d(array as Tensor1D, start, size);\n      case 2:\n        switch (axis) {\n          case 1:\n            return sliceAlongFirstAxis(array, start, size);\n          case 2:\n            return sliceAlongLastAxis(array, start, size);\n          default:\n            throw new ValueError(\n                `The axis is not within the rank of the tensor ` +\n                `${axis}`);\n        }\n      case 3:\n        switch (axis) {\n          case 1:\n            return sliceAlongFirstAxis(array, start, size);\n          case 2:\n            return tfc.slice3d(\n                array as Tensor3D, [0, start, 0],\n                [array.shape[0], size, array.shape[2]]);\n          case 3:\n            return sliceAlongLastAxis(array, start, size);\n          default:\n            throw new ValueError(\n                `The axis is not within the rank of the tensor ` +\n                `${axis}`);\n        }\n      case 4:\n        switch (axis) {\n          case 1:\n            return sliceAlongFirstAxis(array, start, size);\n          case 2:\n            return tfc.slice4d(\n                array as Tensor4D, [0, start, 0, 0],\n                [array.shape[0], size, array.shape[2], array.shape[3]]);\n          case 3:\n            return tfc.slice4d(\n                array as Tensor4D, [0, 0, start, 0],\n                [array.shape[0], array.shape[1], size, array.shape[3]]);\n          case 4:\n            return sliceAlongLastAxis(array, start, size);\n          default:\n            throw new ValueError(\n                `The axis is not within the rank of the tensor ` +\n                `${axis}`);\n        }\n      default:\n        throw new ValueError(\n            `sliceAlongLastAxis() received an unsupported tensor rank: ` +\n            `${array.rank}`);\n    }\n  });\n}\n\n/**\n * Concatenates a list of tensors alongside the specified axis.\n * @param tensors `Array` of tensors to concatenate.\n * @param axis Concatenation axis.\n * @returns The result of the concatenation.\n */\nexport function concatenate(tensors: Tensor[], axis = -1): Tensor {\n  let rank: number;\n  if (axis < 0) {\n    rank = tensors[0].rank;\n    if (rank !== 0) {\n      axis = rank;\n    } else {\n      axis = 0;\n    }\n  }\n  if (axis === tensors[0].rank) {\n    // Porting Note: This is necessary because tfc.concat() requires axis to be\n    //   in the interval [-rank, rank).\n    axis = -1;\n  }\n  // Porting Note: Sparse concat is not supported yet.\n  return tfc.concat(tensors, axis);\n}\n\n/**\n * Concatenate two arrays along the first dimension.\n * @param a The 1st `tf.Tensor` to concatenate.\n * @param b The 2nd `tf.Tensor` to concatenate.\n * @returns Result of the concatenation.\n * @throws ValueError: If `a` is of an unsupported subtype of `tf.Tensor`.\n */\nexport function concatAlongFirstAxis(a: Tensor, b: Tensor): Tensor {\n  switch (a.rank) {\n    case 1:\n      return tfc.concat1d([a as Tensor1D, b as Tensor1D]);\n    case 2:\n      return tfc.concat2d([a as Tensor2D, b as Tensor2D], 0);\n    case 3:\n      return tfc.concat3d([a as Tensor3D, b as Tensor3D], 0);\n    case 4:\n      return tfc.concat4d([a as Tensor4D, b as Tensor4D], 0);\n    default:\n      throw new ValueError(\n          `concatAlongFirstAxis() received an unsupported ` +\n          `tensor rank: ${a.rank}`);\n  }\n}\n\n/**\n * Creates a tensor by tiling `x` by `n`.\n * @param x A tensor.\n * @param n An Array of integers or a single integer. If an Array, the length\n *   must be the same as the number of dimensions in `x`. If a single integer,\n *   it will be treated as an Array of length 1.\n */\nexport function tile(x: Tensor, n: number|number[]): Tensor {\n  if (!Array.isArray(n)) {\n    n = [n];\n  }\n  if (x.rank !== n.length) {\n    throw new ValueError(\n        `The length of input n (${n.length}) does not match ` +\n        `the number of dimensions in input x (${x.rank})`);\n  }\n  return tfc.tile(x, n);\n}\n\n/* Creation of random tensors. */\n\n/**\n * Get a tensor with normal distribution of values.\n *\n * @param shape Shape of the tensor.\n * @param mean mean value of the normal distribution.\n * @param stddev standard deviation of the normal distribution.\n * @param dtype\n * @param seed\n * @return The normal tensor.\n */\nexport function randomNormal(\n    shape: Shape, mean = 0.0, stddev = 1.0, dtype?: 'float32'|'int32',\n    seed?: number): Tensor {\n  return tfc.randomNormal(shape, mean, stddev, dtype, seed);\n}\n\n/* Linear Algebra */\n\n/**\n * Multiply two tensors and returns the result as a tensor.\n *\n * For 2D tensors, this is equivalent to matrix multiplication (matMul).\n * For tensors of higher ranks, it follows the Theano behavior,\n * (e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`).  From the Theano documentation:\n *\n * For N dimensions it is a sum product over the last axis of x and the\n * second-to-last of y:\n *\n * @param a A tensor of at least rank 2.\n * @param b A tensor of at least rank 2.\n * @param activation (optional) A string identifying the activation\n *   function.\n * @return Result of the dot operation.\n */\nexport function dot(\n    a: Tensor, b: Tensor, activation?: tfc.fused.Activation,\n    bias?: Tensor): Tensor {\n  if ((a.rank < 2) || (b.rank < 2)) {\n    throw new NotImplementedError(\n        `dot requires both inputs to be rank >= 2` +\n        ` but got x shape = ${a.shape} and y shape = ${b.shape}`);\n  }\n  if (b.rank >= 3) {\n    const xLastDim = a.shape.slice(-1)[0];\n    const ySecondLastDim = b.shape.slice(-2)[0];\n    if (xLastDim !== ySecondLastDim) {\n      throw new NotImplementedError(\n          `If rank y >= 3, then the second last dim` +\n          ` of y must equal the last dim of x but got x shape = ${\n              a.shape} and ` +\n          ` y shape = ${b.shape}`);\n    }\n  }\n  // Handle basic 2D x 2D case.\n  if ((a.rank === 2) && (b.rank === 2)) {\n    const transposeA = false;\n    const transposeB = false;\n    // tfc.fused.matMul only fuses certain activation functions. Unsupported\n    // activation functions are treated as 'linear' activations, which is\n    // equivalent to a no-op.\n    return tfc.fused.matMul({\n      a,\n      b: b as Tensor2D,\n      transposeA,\n      transposeB,\n      bias: bias ? reshapeBias(a.rank, bias, imageDataFormat()) : null,\n      activation\n    });\n  } else {\n    // Reshape x into the analogous 2D Tensor.\n    const aFirstDims = a.shape.slice();  // Holds all but the last dim of x.\n    const aLastDim = aFirstDims.pop();\n    a = tfc.reshape(a, [-1, aLastDim]);\n\n    // Reshape y into the analogous 2D Tensor, and keep track of the\n    // required dimensions to reproduce the output shape.\n    const bShape = b.shape.slice();\n    const bLastDim = bShape.pop();\n    const ySecondLastDim = bShape.pop();\n    const yOtherDims = [...bShape, bLastDim];\n    // permutation should be like [r-2, 0, 1, 2, ... r-4, r-3, r-1]\n    // where r is the rank of y.\n    const perm = Array.from({length: b.rank}, (_, i) => {\n      if (i === 0) {\n        return b.rank - 2;\n      } else if (i <= b.rank - 2) {\n        return i - 1;\n      }\n      return i;\n    });\n    b = tfc.reshape(tfc.transpose(b, perm), [ySecondLastDim, -1]);\n\n    // Multiply x and y as 2D Tensors, and then reshape back to original.\n    const outputShape = [...aFirstDims, ...yOtherDims];\n    const transposeA = false;\n    const transposeB = false;\n    return tfc.reshape(\n        tfc.fused.matMul({\n          a,\n          b,\n          transposeA,\n          transposeB,\n          bias: bias ? reshapeBias(a.rank, bias, imageDataFormat()) : null,\n          activation\n        }),\n        outputShape);\n  }\n}\n\n/**\n * Compute the sign Tensor of an input Tensor.\n *\n * Elements of the input `tf.Tensor` that are === 0 are mapped to 0.\n * Elements of the input `tf.Tensor` that are > 0 are mapped to 1.\n * Elements of the input `tf.Tensor` that are < 0 are mapped to -1.\n *\n * @param x Input `tf.Tensor`.\n * @return The sign `tf.Tensor`.\n */\nexport function sign(x: Tensor): Tensor {\n  // TODO(cais): Move to the core.\n  return tidy(() => {\n    const zerosLikeX = coreZerosLike(x);\n    const onesLikeX = coreOnesLike(x);\n    return where(\n        tfc.equal(x, zerosLikeX), zerosLikeX,\n        where(\n            tfc.greater(x, coreZerosLike(x)), onesLikeX,\n            tfc.mul(-1, onesLikeX)));\n  });\n}\n\n/**\n * Computes the one-hot representation of an integer tensor.\n * @param indices nD integer tensor of shape\n *   `(batch_size, dim1, dim2, ... dim(n-1))`\n * @param numClasses Integer, number of classes to consider.\n * @returns (n + 1)D one hot representation of the input\n *   with shape `(batch_size, dim1, dim2, ... dim(n-1), num_classes)`\n */\nexport function oneHot(indices: Tensor, numClasses: number): Tensor {\n  return tidy(() => {\n    if (indices.rank !== 1) {\n      throw new Error(\n          'Only 1D one-hot tensors are supported in the ' +\n          'deeplearn backend, at present.');\n    }\n    indices = tfc.cast(indices, 'int32');\n    return tfc.cast(tfc.oneHot(indices as Tensor1D, numClasses), 'float32');\n  });\n}\n\n/* Elementary math functions. */\n\n/**\n * Retrieves the elements of indices `indices` in the tensor `reference`.\n * @param reference A tensor.\n * @param indices An integer tensor of indices or an `Array` of integers.\n * @param axis Axis along which to perform the gather operation.\n * @returns The result of the gathering as a tensor.\n */\nexport function gather(\n    reference: Tensor, indices: number[]|Tensor1D, axis?: number): Tensor {\n  return tidy(() => {\n    if (Array.isArray(indices)) {\n      indices = tensor1d(indices, 'int32');\n    } else {\n      indices = tfc.cast(indices, 'int32');\n    }\n    return tfc.gather(reference, indices, axis);\n  });\n}\n\n/**\n * Element-wise square.\n * @param x Input tensor.\n * @return element-wise x^2\n */\nexport function square(x: Tensor): Tensor {\n  return tfc.mul(x, x);\n}\n\n/**\n * Element-wise exponentiation.\n *\n * Porting Note: In PyKeras, `a` (the exponent) is a Python integer, which\n *   takes advatnage of the backend's (e.g., TensorFlow's) automatic\n * conversion to tensor. Here we allow `a` to be either a number or a tensor.\n *\n * @param x The base tensor.\n * @param a The exponent, tensor or number. If a number, it is rounded to the\n *   nearest integer and converted to a tensor.\n * @returns A tensor of the same shape as `x`.\n */\nexport function pow(x: Tensor, a: Tensor|number): Tensor {\n  return tidy(() => {\n    if (typeof (a) === 'number') {\n      a = scalar(Math.round(a), 'int32');\n    }\n    if (a.dtype !== 'int32') {\n      throw new NotImplementedError(\n          `Non-int32 dtype (${a.dtype}) is not supported by pow() yet`);\n    }\n    return tfc.pow(x, a);\n  });\n}\n\n/**\n * Reshapes bias tensor according to rank of x.\n */\nfunction reshapeBias(xRank: number, bias: Tensor, dataFormat: string) {\n  const biasShape = bias.shape;\n\n  if (bias.rank !== 1 && bias.rank !== xRank) {\n    throw new ValueError(\n        `Unexpected bias dimensions: ${bias.rank}` +\n        `; expected it to be 1 or ${xRank}`);\n  }\n\n  if (xRank === 5) {\n    if (dataFormat === 'channelsFirst') {\n      if (biasShape.length === 1) {\n        return tfc.reshape(bias, [1, biasShape[0], 1, 1, 1]);\n      } else {\n        return tfc.reshape(\n            bias, [1, biasShape[3], biasShape[0], biasShape[1], biasShape[2]]);\n      }\n    } else if (dataFormat === 'channelsLast') {\n      if (biasShape.length === 1) {\n        return tfc.reshape(bias, [1, 1, 1, 1, biasShape[0]]);\n      } else {\n        return tfc.reshape(bias, [1].concat(biasShape));\n      }\n    }\n  } else if (xRank === 4) {\n    if (dataFormat === 'channelsFirst') {\n      if (biasShape.length === 1) {\n        return tfc.reshape(bias, [1, biasShape[0], 1, 1]);\n      } else {\n        return tfc.reshape(bias, [1, biasShape[2], biasShape[0], biasShape[1]]);\n      }\n    } else if (dataFormat === 'channelsLast') {\n      if (biasShape.length === 1) {\n        return tfc.reshape(bias, [1, 1, 1, biasShape[0]]);\n      } else {\n        return tfc.reshape(bias, [1].concat(biasShape));\n      }\n    }\n  } else if (xRank === 3) {\n    if (dataFormat === 'channelsFirst') {\n      if (biasShape.length === 1) {\n        return tfc.reshape(bias, [1, biasShape[0], 1]);\n      } else {\n        return tfc.reshape(bias, [1, biasShape[1], biasShape[0]]);\n      }\n    } else if (dataFormat === 'channelsLast') {\n      if (biasShape.length === 1) {\n        return tfc.reshape(bias, [1, 1, biasShape[0]]);\n      } else {\n        return tfc.reshape(bias, [1].concat(biasShape));\n      }\n    }\n  } else if (xRank < 3) {\n    return bias;\n  }\n  throw new ValueError(`Unsupported input rank by biasAdd: ${bias.rank}`);\n}\n\n/* Neural-network operations. */\n\n/**\n * Add a bias to a tensor.\n *\n * @param x The tensor to add the bias to.\n * @param bias The bias to add to `x`. Must be 1D or the same rank as `x`.\n * @return Result of the bias adding.\n * @throws ValueError: If the rank of `bias` is incorrect.\n */\nexport function biasAdd(\n    x: Tensor, bias: Tensor, dataFormat?: DataFormat): Tensor {\n  return tidy(() => {\n    if (dataFormat == null) {\n      dataFormat = imageDataFormat();\n    }\n    checkDataFormat(dataFormat);\n\n    return tfc.add(x, reshapeBias(x.rank, bias, dataFormat));\n  });\n}\n\n/**\n * Exponential linear unit (ELU).\n * @param x A tensor or variable to compute the activation function for.\n * @param alpha: A scalar, a scaling factor for the negative section.\n * @return Output of the ELU operation.\n */\nexport function elu(x: Tensor, alpha = 1): Tensor {\n  // TODO(cais): Add support for alpha values other than 1.\n  if (alpha !== 1) {\n    throw new NotImplementedError(\n        `Support for alpha values other than 1 (${alpha}) is not implemented ` +\n        `yet.`);\n  }\n  return tfc.elu(x);\n}\n\n/**\n * Softsign of a tensor.\n *\n * Defined as x / (abs(x) + 1), element-wise.\n *\n * @param x: Input.\n * @returns Output.\n */\nexport function softsign(x: Tensor): Tensor {\n  return tidy(() => tfc.div(x, tfc.add(tfc.abs(x), 1)));\n}\n\n/**\n * Sets entries in `x` to zero at random, while scaling the entire tensor.\n *\n * @param x input tensor.\n * @param level fraction of the entries in the tensor that will be set to 0.\n * @param noiseShape shape of randomly generated keep/drop flags, must be\n *   broadcastable to the shape of `x`. Optional.\n * @param seed random seed to ensure determinism. Optional.\n * @returns Result of the dropout operation.\n */\nexport function dropout(\n    x: Tensor, level: number, noiseShape?: number[], seed?: number): Tensor {\n  return tidy(() => tfc.dropout(x, level, noiseShape, seed));\n}\n\n/**\n * Element-wise, segment-wise linear approximation of sigmoid.\n *\n * Returns `0.` if `x < -2.5`, `1.` if `x > 2.5`.\n * In `-2.5 <= x <= 2.5`, returns `0.2 * x + 0.5`.\n *\n * @param x Input tensor.\n * @returns Output tensor.\n */\nexport function hardSigmoid(x: Tensor): Tensor {\n  return tidy(() => {\n    const y = tfc.add(.5, tfc.mul(.2, x));\n    return tfc.clipByValue(y, 0, 1);\n  });\n}\n\n/**\n * Invoke `x` in the training phase, and `alt` otherwise.\n *\n * Porting Note: We do not create placeholder tensors for the `training`\n * boolean flag here, because there is no such thing in the TF.js imperative\n * backend.\n *\n * @param x The function to invoke iff `training` is `true`.\n * @param alt The function to invoke iff `training` is `false`.\n * @param training Boolean flag for whether training phase is active.\n * @returns The return value of `x()` if `training` is `true`, or the return\n *   value of `alt()` if `training` is `false`.\n */\nexport function inTrainPhase<T>(x: () => T, alt: () => T, training = false): T {\n  return training ? x() : alt();\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;GAQG,CAEH;;GAEG;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAEH,OAAO,KAAK,GAAG,MAAM,uBAAuB,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAC7C,OAAO,EAAC,QAAQ,IAAI,YAAY,EAAE,MAAM,EAAoB,QAAQ,EAA0C,IAAI,EAAE,KAAK,EAAE,SAAS,IAAI,aAAa,EAAC,MAAM,uBAAuB,CAAC;AACpL,OAAO,EAAC,eAAe,EAAC,MAAM,WAAW,CAAC;AAC1C,OAAO,EAAC,mBAAmB,EAAE,UAAU,EAAC,MAAM,WAAW,CAAC;AAG1D,OAAO,KAAK,UAAU,MAAM,qBAAqB,CAAC;AAElD,OAAO,EAAC,eAAe,EAAC,MAAM,UAAU,CAAC;;;;;;;AAEzC,gBAAgB;AAEhB,kDAAA,EAAoD,CAEpD,+CAA+C;AAC/C,IAAI,OAAO,GAAkB,OAAO,CAAC;AAE/B,SAAU,UAAU,CAAC,gBAA+B;IACxD,GAAG,CAAC,gLAAA,AAAU,EAAC,gBAAgB,CAAC,CAAC;IACjC,OAAO,GAAG,gBAAgB,CAAC;AAC7B,CAAC;AAEK,SAAU,UAAU;IACxB,OAAO,OAAO,CAAC;AACjB,CAAC;AASK,SAAU,iBAAiB;IAC/B,OAAO,KAAK,CAAC;AACf,CAAC;AAOK,SAAU,WAAW,CAAC,CAAW;IACrC,MAAM,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC;IACtB,IAAI,KAAK,CAAC,MAAM,GAAG,CAAC,EAAE;QACpB,OAAO,KAAK,CAAC,MAAM,CAAC,CAAC,CAAS,EAAE,CAAS,EAAE,CAAG,CAAD,AAAE,GAAG,CAAC,CAAC,CAAC;KACtD,MAAM;QACL,UAAU;QACV,OAAO,CAAC,CAAC;KACV;AACH,CAAC;AAQK,SAAU,IAAI,CAAC,CAAS,EAAE,KAAmB;IACjD,OAAO,GAAG,CAAC,8KAAA,AAAI,EAAC,CAAC,EAAE,KAAK,CAAC,CAAC;AAC5B,CAAC;AAQK,SAAU,UAAU,CAAC,CAAS,EAAE,IAAI,GAAG,CAAC,CAAC;IAC7C,MAAM,QAAQ,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC;IACjC,IAAI,IAAI,GAAG,CAAC,EAAE;QACZ,IAAI,GAAG,QAAQ,CAAC,MAAM,GAAG,IAAI,GAAG,CAAC,CAAC;KACnC;IACD,QAAQ,CAAC,MAAM,CAAC,IAAI,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;IAC5B,qLAAO,GAAG,CAAC,MAAA,AAAO,EAAC,CAAC,EAAE,QAAQ,CAAC,CAAC;AAClC,CAAC;AAaK,SAAU,MAAM,CAAC,CAAS,EAAE,CAAS;IACzC,8KAAO,OAAA,AAAI,EAAC,GAAG,EAAE;QACf,IAAI,CAAC,CAAC,KAAK,CAAC,MAAM,KAAK,CAAC,EAAE;YACxB,MAAM,wKAAI,aAAU,CAChB,CAAA,iDAAA,CAAmD,GACnD,CAAA,KAAA,EAAQ,CAAC,CAAC,KAAK,CAAC,MAAM,CAAA,QAAA,CAAU,CAAC,CAAC;SACvC;QACD,MAAM,CAAC,GAAG,UAAU,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QAC3B,OAAO,IAAI,CAAC,CAAC,EAAE;YAAC,CAAC;YAAE,CAAC;YAAE,CAAC;SAAC,CAAC,CAAC;IAC5B,CAAC,CAAC,CAAC;AACL,CAAC;AAOK,SAAU,OAAO,CAAC,CAAS;IAC/B,MAAM,QAAQ,GAAG;6LAAC,UAAU,CAAC,CAAA,AAAS,EAAC,CAAC,CAAC,KAAK,CAAC;KAAC,CAAC;IACjD,qLAAO,GAAG,CAAC,MAAA,AAAO,EAAC,CAAC,EAAE,QAAQ,CAAC,CAAC;AAClC,CAAC;AAUK,SAAU,YAAY,CAAC,CAAS;IACpC,IAAI,CAAC,CAAC,IAAI,IAAI,CAAC,EAAE;QACf,MAAM,wKAAI,aAAU,CAChB,CAAA,qDAAA,EAAwD,CAAC,CAAC,IAAI,CAAA,CAAA,CAAG,CAAC,CAAC;KACxE;IACD,MAAM,QAAQ,GAAG;QAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC;6LAAE,UAAU,CAAC,CAAA,AAAS,EAAC,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC;KAAC,CAAC;IAChE,oLAAO,GAAG,CAAC,OAAA,AAAO,EAAC,CAAC,EAAE,QAAQ,CAAC,CAAC;AAClC,CAAC;AAUK,SAAU,mBAAmB,CAC/B,KAAa,EAAE,KAAa,EAAE,IAAY;IAC5C,8KAAO,OAAA,AAAI,EAAC,GAAG,EAAE;QACf,OAAQ,KAAK,CAAC,IAAI,EAAE;YAClB,KAAK,CAAC;gBACJ,qLAAO,GAAG,CAAC,MAAO,AAAP,EAAQ,KAAiB,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;YACrD,KAAK,CAAC;gBACJ,OAAO,GAAG,CAAC,oLAAA,AAAO,EACd,KAAiB,EAAE;oBAAC,KAAK;oBAAE,CAAC;iBAAC,EAAE;oBAAC,IAAI;oBAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;iBAAC,CAAC,CAAC;YAC7D,KAAK,CAAC;gBACJ,qLAAO,GAAG,CAAC,MAAA,AAAO,EACd,KAAiB,EAAE;oBAAC,KAAK;oBAAE,CAAC;oBAAE,CAAC;iBAAC,EAChC;oBAAC,IAAI;oBAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;oBAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;iBAAC,CAAC,CAAC;YAC9C,KAAK,CAAC;gBACJ,OAAO,GAAG,CAAC,oLAAA,AAAO,EACd,KAAiB,EAAE;oBAAC,KAAK;oBAAE,CAAC;oBAAE,CAAC;oBAAE,CAAC;iBAAC,EACnC;oBAAC,IAAI;oBAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;oBAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;oBAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;iBAAC,CAAC,CAAC;YAC9D,KAAK,CAAC;gBACJ,QAAO,GAAG,CAAC,+KAAK,AAAL,EAAM,KAAiB,EAAE;oBAAC,KAAK;oBAAE,CAAC;oBAAE,CAAC;oBAAE,CAAC;oBAAE,CAAC;iBAAC,EAAE;oBACvD,IAAI;oBAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;oBAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;oBAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;oBAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;iBACrE,CAAC,CAAC;YACL,KAAK,CAAC;gBACJ,mLAAO,GAAG,CAAC,IAAA,AAAK,EAAC,KAAK,EAAE;oBAAC,KAAK;oBAAE,CAAC;oBAAE,CAAC;oBAAE,CAAC;oBAAE,CAAC;oBAAE,CAAC;iBAAC,EAAE;oBAC9C,IAAI;oBAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;oBAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;oBAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;oBAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;oBACpE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;iBACf,CAAC,CAAC;YACL;gBACE,MAAM,wKAAI,aAAU,CAChB,CAAA,2DAAA,CAA6D,GAC7D,GAAG,KAAK,CAAC,IAAI,EAAE,CAAC,CAAC;SACxB;IACH,CAAC,CAAC,CAAC;AACL,CAAC;AAUK,SAAU,kBAAkB,CAC9B,KAAa,EAAE,KAAa,EAAE,IAAY;IAC5C,8KAAO,OAAA,AAAI,EAAC,GAAG,EAAE;QACf,OAAQ,KAAK,CAAC,IAAI,EAAE;YAClB,KAAK,CAAC;gBACJ,qLAAO,GAAG,CAAC,MAAO,AAAP,EAAQ,KAAiB,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;YACrD,KAAK,CAAC;gBACJ,qLAAO,GAAG,CAAC,MAAA,AAAO,EACd,KAAiB,EAAE;oBAAC,CAAC;oBAAE,KAAK;iBAAC,EAAE;oBAAC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;oBAAE,IAAI;iBAAC,CAAC,CAAC;YAC7D,KAAK,CAAC;gBACJ,qLAAO,GAAG,CAAC,MAAA,AAAO,EACd,KAAiB,EAAE;oBAAC,CAAC;oBAAE,CAAC;oBAAE,KAAK;iBAAC,EAChC;oBAAC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;oBAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;oBAAE,IAAI;iBAAC,CAAC,CAAC;YAC9C,KAAK,CAAC;gBACJ,OAAO,GAAG,CAAC,oLAAA,AAAO,EACd,KAAiB,EAAE;oBAAC,CAAC;oBAAE,CAAC;oBAAE,CAAC;oBAAE,KAAK;iBAAC,EACnC;oBAAC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;oBAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;oBAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;oBAAE,IAAI;iBAAC,CAAC,CAAC;YAC9D;gBACE,MAAM,wKAAI,aAAU,CAChB,CAAA,0DAAA,CAA4D,GAC5D,GAAG,KAAK,CAAC,IAAI,EAAE,CAAC,CAAC;SACxB;IACH,CAAC,CAAC,CAAC;AACL,CAAC;AAWK,SAAU,cAAc,CAC1B,KAAa,EAAE,KAAa,EAAE,IAAY,EAAE,IAAY;IAC1D,6KAAO,QAAA,AAAI,EAAC,GAAG,EAAE;QACf,OAAQ,KAAK,CAAC,IAAI,EAAE;YAClB,KAAK,CAAC;gBACJ,WAAO,GAAG,CAAC,gLAAA,AAAO,EAAC,KAAiB,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;YACrD,KAAK,CAAC;gBACJ,OAAQ,IAAI,EAAE;oBACZ,KAAK,CAAC;wBACJ,OAAO,mBAAmB,CAAC,KAAK,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;oBACjD,KAAK,CAAC;wBACJ,OAAO,kBAAkB,CAAC,KAAK,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;oBAChD;wBACE,MAAM,wKAAI,aAAU,CAChB,CAAA,8CAAA,CAAgD,GAChD,GAAG,IAAI,EAAE,CAAC,CAAC;iBAClB;YACH,KAAK,CAAC;gBACJ,OAAQ,IAAI,EAAE;oBACZ,KAAK,CAAC;wBACJ,OAAO,mBAAmB,CAAC,KAAK,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;oBACjD,KAAK,CAAC;wBACJ,qLAAO,GAAG,CAAC,MAAA,AAAO,EACd,KAAiB,EAAE;4BAAC,CAAC;4BAAE,KAAK;4BAAE,CAAC;yBAAC,EAChC;4BAAC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;4BAAE,IAAI;4BAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;yBAAC,CAAC,CAAC;oBAC9C,KAAK,CAAC;wBACJ,OAAO,kBAAkB,CAAC,KAAK,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;oBAChD;wBACE,MAAM,wKAAI,aAAU,CAChB,CAAA,8CAAA,CAAgD,GAChD,GAAG,IAAI,EAAE,CAAC,CAAC;iBAClB;YACH,KAAK,CAAC;gBACJ,OAAQ,IAAI,EAAE;oBACZ,KAAK,CAAC;wBACJ,OAAO,mBAAmB,CAAC,KAAK,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;oBACjD,KAAK,CAAC;wBACJ,qLAAO,GAAG,CAAC,MAAO,AAAP,EACP,KAAiB,EAAE;4BAAC,CAAC;4BAAE,KAAK;4BAAE,CAAC;4BAAE,CAAC;yBAAC,EACnC;4BAAC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;4BAAE,IAAI;4BAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;4BAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;yBAAC,CAAC,CAAC;oBAC9D,KAAK,CAAC;wBACJ,qLAAO,GAAG,CAAC,MAAA,AAAO,EACd,KAAiB,EAAE;4BAAC,CAAC;4BAAE,CAAC;4BAAE,KAAK;4BAAE,CAAC;yBAAC,EACnC;4BAAC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;4BAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;4BAAE,IAAI;4BAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;yBAAC,CAAC,CAAC;oBAC9D,KAAK,CAAC;wBACJ,OAAO,kBAAkB,CAAC,KAAK,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;oBAChD;wBACE,MAAM,wKAAI,aAAU,CAChB,CAAA,8CAAA,CAAgD,GAChD,GAAG,IAAI,EAAE,CAAC,CAAC;iBAClB;YACH;gBACE,MAAM,wKAAI,aAAU,CAChB,CAAA,0DAAA,CAA4D,GAC5D,GAAG,KAAK,CAAC,IAAI,EAAE,CAAC,CAAC;SACxB;IACH,CAAC,CAAC,CAAC;AACL,CAAC;AAQK,SAAU,WAAW,CAAC,OAAiB,EAAE,IAAI,GAAG,CAAC,CAAC;IACtD,IAAI,IAAY,CAAC;IACjB,IAAI,IAAI,GAAG,CAAC,EAAE;QACZ,IAAI,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC;QACvB,IAAI,IAAI,KAAK,CAAC,EAAE;YACd,IAAI,GAAG,IAAI,CAAC;SACb,MAAM;YACL,IAAI,GAAG,CAAC,CAAC;SACV;KACF;IACD,IAAI,IAAI,KAAK,OAAO,CAAC,CAAC,CAAC,CAAC,IAAI,EAAE;QAC5B,2EAA2E;QAC3E,mCAAmC;QACnC,IAAI,GAAG,CAAC,CAAC,CAAC;KACX;IACD,oDAAoD;IACpD,OAAO,GAAG,CAAC,kLAAM,AAAN,EAAO,OAAO,EAAE,IAAI,CAAC,CAAC;AACnC,CAAC;AASK,SAAU,oBAAoB,CAAC,CAAS,EAAE,CAAS;IACvD,OAAQ,CAAC,CAAC,IAAI,EAAE;QACd,KAAK,CAAC;YACJ,sLAAO,GAAG,CAAC,QAAA,AAAQ,EAAC;gBAAC,CAAa;gBAAE,CAAa;aAAC,CAAC,CAAC;QACtD,KAAK,CAAC;YACJ,uLAAO,GAAG,CAAC,OAAQ,AAAR,EAAS;gBAAC,CAAa;gBAAE,CAAa;aAAC,EAAE,CAAC,CAAC,CAAC;QACzD,KAAK,CAAC;YACJ,uLAAO,GAAG,CAAC,OAAA,AAAQ,EAAC;gBAAC,CAAa;gBAAE,CAAa;aAAC,EAAE,CAAC,CAAC,CAAC;QACzD,KAAK,CAAC;YACJ,uLAAO,GAAG,CAAC,OAAA,AAAQ,EAAC;gBAAC,CAAa;gBAAE,CAAa;aAAC,EAAE,CAAC,CAAC,CAAC;QACzD;YACE,MAAM,wKAAI,aAAU,CAChB,CAAA,+CAAA,CAAiD,GACjD,CAAA,aAAA,EAAgB,CAAC,CAAC,IAAI,EAAE,CAAC,CAAC;KACjC;AACH,CAAC;AASK,SAAU,IAAI,CAAC,CAAS,EAAE,CAAkB;IAChD,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE;QACrB,CAAC,GAAG;YAAC,CAAC;SAAC,CAAC;KACT;IACD,IAAI,CAAC,CAAC,IAAI,KAAK,CAAC,CAAC,MAAM,EAAE;QACvB,MAAM,IAAI,iLAAU,CAChB,CAAA,uBAAA,EAA0B,CAAC,CAAC,MAAM,CAAA,iBAAA,CAAmB,GACrD,CAAA,qCAAA,EAAwC,CAAC,CAAC,IAAI,CAAA,CAAA,CAAG,CAAC,CAAC;KACxD;IACD,kLAAO,GAAG,CAAC,GAAA,AAAI,EAAC,CAAC,EAAE,CAAC,CAAC,CAAC;AACxB,CAAC;AAcK,SAAU,YAAY,CACxB,KAAY,EAAE,IAAI,GAAG,GAAG,EAAE,MAAM,GAAG,GAAG,EAAE,KAAyB,EACjE,IAAa;IACf,QAAO,GAAG,CAAC,8LAAA,AAAY,EAAC,KAAK,EAAE,IAAI,EAAE,MAAM,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;AAC5D,CAAC;AAoBK,SAAU,GAAG,CACf,CAAS,EAAE,CAAS,EAAE,UAAiC,EACvD,IAAa;IACf,IAAI,AAAC,CAAC,CAAC,IAAI,GAAG,CAAC,CAAC,GAAK,CAAD,AAAE,CAAC,IAAI,GAAG,CAAC,CAAC,CAAE;QAChC,MAAM,IAAI,0LAAmB,CACzB,CAAA,wCAAA,CAA0C,GAC1C,CAAA,mBAAA,EAAsB,CAAC,CAAC,KAAK,CAAA,eAAA,EAAkB,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC;KAC/D;IACD,IAAI,CAAC,CAAC,IAAI,IAAI,CAAC,EAAE;QACf,MAAM,QAAQ,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,cAAc,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAC5C,IAAI,QAAQ,KAAK,cAAc,EAAE;YAC/B,MAAM,wKAAI,sBAAmB,CACzB,CAAA,wCAAA,CAA0C,GAC1C,CAAA,qDAAA,EACI,CAAC,CAAC,KAAK,CAAA,KAAA,CAAO,GAClB,CAAA,WAAA,EAAc,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC;SAC9B;KACF;IACD,6BAA6B;IAC7B,IAAI,AAAC,CAAC,CAAC,IAAI,KAAK,CAAC,CAAC,GAAK,CAAD,AAAE,CAAC,IAAI,KAAK,CAAC,CAAC,CAAE;QACpC,MAAM,UAAU,GAAG,KAAK,CAAC;QACzB,MAAM,UAAU,GAAG,KAAK,CAAC;QACzB,wEAAwE;QACxE,qEAAqE;QACrE,yBAAyB;QACzB,oNAAO,GAAG,CAAC,IAAK,CAAC,MAAM,CAAC;YACtB,CAAC;YACD,CAAC,EAAE,CAAa;YAChB,UAAU;YACV,UAAU;YACV,IAAI,EAAE,IAAI,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,IAAI,EAAE,IAAI,qLAAE,kBAAA,AAAe,EAAE,CAAC,CAAC,CAAC,EAAC,IAAI;YAChE,UAAU;SACX,CAAC,CAAC;KACJ,MAAM;QACL,0CAA0C;QAC1C,MAAM,UAAU,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC,CAAE,mCAAmC;QACxE,MAAM,QAAQ,GAAG,UAAU,CAAC,GAAG,EAAE,CAAC;QAClC,CAAC,iLAAG,GAAG,CAAC,MAAA,AAAO,EAAC,CAAC,EAAE;YAAC,CAAC,CAAC;YAAE,QAAQ;SAAC,CAAC,CAAC;QAEnC,gEAAgE;QAChE,qDAAqD;QACrD,MAAM,MAAM,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC;QAC/B,MAAM,QAAQ,GAAG,MAAM,CAAC,GAAG,EAAE,CAAC;QAC9B,MAAM,cAAc,GAAG,MAAM,CAAC,GAAG,EAAE,CAAC;QACpC,MAAM,UAAU,GAAG,CAAC;eAAG,MAAM;YAAE,QAAQ;SAAC,CAAC;QACzC,+DAA+D;QAC/D,4BAA4B;QAC5B,MAAM,IAAI,GAAG,KAAK,CAAC,IAAI,CAAC;YAAC,MAAM,EAAE,CAAC,CAAC,IAAI;QAAA,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE;YACjD,IAAI,CAAC,KAAK,CAAC,EAAE;gBACX,OAAO,CAAC,CAAC,IAAI,GAAG,CAAC,CAAC;aACnB,MAAM,IAAI,CAAC,IAAI,CAAC,CAAC,IAAI,GAAG,CAAC,EAAE;gBAC1B,OAAO,CAAC,GAAG,CAAC,CAAC;aACd;YACD,OAAO,CAAC,CAAC;QACX,CAAC,CAAC,CAAC;QACH,CAAC,iLAAG,GAAG,CAAC,MAAA,AAAO,kLAAC,GAAG,CAAC,QAAS,AAAT,EAAU,CAAC,EAAE,IAAI,CAAC,EAAE;YAAC,cAAc;YAAE,CAAC,CAAC;SAAC,CAAC,CAAC;QAE9D,qEAAqE;QACrE,MAAM,WAAW,GAAG,CAAC;eAAG,UAAU,EAAE;eAAG,UAAU;SAAC,CAAC;QACnD,MAAM,UAAU,GAAG,KAAK,CAAC;QACzB,MAAM,UAAU,GAAG,KAAK,CAAC;QACzB,WAAO,GAAG,CAAC,gLAAA,AAAO,+MACd,GAAG,CAAC,IAAK,CAAC,MAAM,CAAC;YACf,CAAC;YACD,CAAC;YACD,UAAU;YACV,UAAU;YACV,IAAI,EAAE,IAAI,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,IAAI,EAAE,IAAI,oLAAE,mBAAe,AAAf,EAAiB,CAAC,CAAC,CAAC,EAAC,IAAI;YAChE,UAAU;SACX,CAAC,EACF,WAAW,CAAC,CAAC;KAClB;AACH,CAAC;AAYK,SAAU,IAAI,CAAC,CAAS;IAC5B,gCAAgC;IAChC,6KAAO,QAAA,AAAI,EAAC,GAAG,EAAE;QACf,MAAM,UAAU,oLAAG,YAAA,AAAa,EAAC,CAAC,CAAC,CAAC;QACpC,MAAM,SAAS,kLAAG,YAAA,AAAY,EAAC,CAAC,CAAC,CAAC;QAClC,mLAAO,QAAA,AAAK,MACR,GAAG,CAAC,4KAAK,AAAL,EAAM,CAAC,EAAE,UAAU,CAAC,EAAE,UAAU,8KACpC,QAAA,AAAK,gLACD,GAAG,CAAC,MAAA,AAAO,EAAC,CAAC,mLAAE,YAAA,AAAa,EAAC,CAAC,CAAC,CAAC,EAAE,SAAS,4KAC3C,GAAG,CAAC,EAAA,AAAG,EAAC,CAAC,CAAC,EAAE,SAAS,CAAC,CAAC,CAAC,CAAC;IACnC,CAAC,CAAC,CAAC;AACL,CAAC;AAUK,SAAU,MAAM,CAAC,OAAe,EAAE,UAAkB;IACxD,8KAAO,OAAA,AAAI,EAAC,GAAG,EAAE;QACf,IAAI,OAAO,CAAC,IAAI,KAAK,CAAC,EAAE;YACtB,MAAM,IAAI,KAAK,CACX,+CAA+C,GAC/C,gCAAgC,CAAC,CAAC;SACvC;QACD,OAAO,8KAAG,GAAG,CAAC,GAAA,AAAI,EAAC,OAAO,EAAE,OAAO,CAAC,CAAC;QACrC,QAAO,GAAG,CAAC,6KAAI,AAAJ,gLAAK,GAAG,CAAC,KAAA,AAAM,EAAC,OAAmB,EAAE,UAAU,CAAC,EAAE,SAAS,CAAC,CAAC;IAC1E,CAAC,CAAC,CAAC;AACL,CAAC;AAWK,SAAU,MAAM,CAClB,SAAiB,EAAE,OAA0B,EAAE,IAAa;IAC9D,8KAAO,OAAI,AAAJ,EAAK,GAAG,EAAE;QACf,IAAI,KAAK,CAAC,OAAO,CAAC,OAAO,CAAC,EAAE;YAC1B,OAAO,kLAAG,WAAA,AAAQ,EAAC,OAAO,EAAE,OAAO,CAAC,CAAC;SACtC,MAAM;YACL,OAAO,8KAAG,GAAG,CAAC,GAAA,AAAI,EAAC,OAAO,EAAE,OAAO,CAAC,CAAC;SACtC;QACD,QAAO,GAAG,CAAC,iLAAA,AAAM,EAAC,SAAS,EAAE,OAAO,EAAE,IAAI,CAAC,CAAC;IAC9C,CAAC,CAAC,CAAC;AACL,CAAC;AAOK,SAAU,MAAM,CAAC,CAAS;IAC9B,iLAAO,GAAG,CAAC,EAAA,AAAG,EAAC,CAAC,EAAE,CAAC,CAAC,CAAC;AACvB,CAAC;AAcK,SAAU,GAAG,CAAC,CAAS,EAAE,CAAgB;IAC7C,8KAAO,OAAA,AAAI,EAAC,GAAG,EAAE;QACf,IAAI,OAAO,AAAC,CAAC,CAAC,IAAK,QAAQ,EAAE;YAC3B,CAAC,GAAG,sLAAM,AAAN,EAAO,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,OAAO,CAAC,CAAC;SACpC;QACD,IAAI,CAAC,CAAC,KAAK,KAAK,OAAO,EAAE;YACvB,MAAM,wKAAI,sBAAmB,CACzB,CAAA,iBAAA,EAAoB,CAAC,CAAC,KAAK,CAAA,+BAAA,CAAiC,CAAC,CAAC;SACnE;QACD,QAAO,GAAG,CAAC,2KAAG,AAAH,EAAI,CAAC,EAAE,CAAC,CAAC,CAAC;IACvB,CAAC,CAAC,CAAC;AACL,CAAC;AAED;;GAEG,CACH,SAAS,WAAW,CAAC,KAAa,EAAE,IAAY,EAAE,UAAkB;IAClE,MAAM,SAAS,GAAG,IAAI,CAAC,KAAK,CAAC;IAE7B,IAAI,IAAI,CAAC,IAAI,KAAK,CAAC,IAAI,IAAI,CAAC,IAAI,KAAK,KAAK,EAAE;QAC1C,MAAM,wKAAI,aAAU,CAChB,CAAA,4BAAA,EAA+B,IAAI,CAAC,IAAI,EAAE,GAC1C,CAAA,yBAAA,EAA4B,KAAK,EAAE,CAAC,CAAC;KAC1C;IAED,IAAI,KAAK,KAAK,CAAC,EAAE;QACf,IAAI,UAAU,KAAK,eAAe,EAAE;YAClC,IAAI,SAAS,CAAC,MAAM,KAAK,CAAC,EAAE;gBAC1B,qLAAO,GAAG,CAAC,MAAA,AAAO,EAAC,IAAI,EAAE;oBAAC,CAAC;oBAAE,SAAS,CAAC,CAAC,CAAC;oBAAE,CAAC;oBAAE,CAAC;oBAAE,CAAC;iBAAC,CAAC,CAAC;aACtD,MAAM;gBACL,OAAO,GAAG,CAAC,oLAAA,AAAO,EACd,IAAI,EAAE;oBAAC,CAAC;oBAAE,SAAS,CAAC,CAAC,CAAC;oBAAE,SAAS,CAAC,CAAC,CAAC;oBAAE,SAAS,CAAC,CAAC,CAAC;oBAAE,SAAS,CAAC,CAAC,CAAC;iBAAC,CAAC,CAAC;aACxE;SACF,MAAM,IAAI,UAAU,KAAK,cAAc,EAAE;YACxC,IAAI,SAAS,CAAC,MAAM,KAAK,CAAC,EAAE;gBAC1B,qLAAO,GAAG,CAAC,MAAA,AAAO,EAAC,IAAI,EAAE;oBAAC,CAAC;oBAAE,CAAC;oBAAE,CAAC;oBAAE,CAAC;oBAAE,SAAS,CAAC,CAAC,CAAC;iBAAC,CAAC,CAAC;aACtD,MAAM;gBACL,qLAAO,GAAG,CAAC,MAAA,AAAO,EAAC,IAAI,EAAE;oBAAC,CAAC;iBAAC,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC,CAAC;aACjD;SACF;KACF,MAAM,IAAI,KAAK,KAAK,CAAC,EAAE;QACtB,IAAI,UAAU,KAAK,eAAe,EAAE;YAClC,IAAI,SAAS,CAAC,MAAM,KAAK,CAAC,EAAE;gBAC1B,qLAAO,GAAG,CAAC,MAAA,AAAO,EAAC,IAAI,EAAE;oBAAC,CAAC;oBAAE,SAAS,CAAC,CAAC,CAAC;oBAAE,CAAC;oBAAE,CAAC;iBAAC,CAAC,CAAC;aACnD,MAAM;gBACL,qLAAO,GAAG,CAAC,MAAA,AAAO,EAAC,IAAI,EAAE;oBAAC,CAAC;oBAAE,SAAS,CAAC,CAAC,CAAC;oBAAE,SAAS,CAAC,CAAC,CAAC;oBAAE,SAAS,CAAC,CAAC,CAAC;iBAAC,CAAC,CAAC;aACzE;SACF,MAAM,IAAI,UAAU,KAAK,cAAc,EAAE;YACxC,IAAI,SAAS,CAAC,MAAM,KAAK,CAAC,EAAE;gBAC1B,OAAO,GAAG,CAAC,oLAAA,AAAO,EAAC,IAAI,EAAE;oBAAC,CAAC;oBAAE,CAAC;oBAAE,CAAC;oBAAE,SAAS,CAAC,CAAC,CAAC;iBAAC,CAAC,CAAC;aACnD,MAAM;gBACL,qLAAO,GAAG,CAAC,MAAA,AAAO,EAAC,IAAI,EAAE;oBAAC,CAAC;iBAAC,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC,CAAC;aACjD;SACF;KACF,MAAM,IAAI,KAAK,KAAK,CAAC,EAAE;QACtB,IAAI,UAAU,KAAK,eAAe,EAAE;YAClC,IAAI,SAAS,CAAC,MAAM,KAAK,CAAC,EAAE;gBAC1B,qLAAO,GAAG,CAAC,MAAO,AAAP,EAAQ,IAAI,EAAE;oBAAC,CAAC;oBAAE,SAAS,CAAC,CAAC,CAAC;oBAAE,CAAC;iBAAC,CAAC,CAAC;aAChD,MAAM;gBACL,QAAO,GAAG,CAAC,mLAAA,AAAO,EAAC,IAAI,EAAE;oBAAC,CAAC;oBAAE,SAAS,CAAC,CAAC,CAAC;oBAAE,SAAS,CAAC,CAAC,CAAC;iBAAC,CAAC,CAAC;aAC3D;SACF,MAAM,IAAI,UAAU,KAAK,cAAc,EAAE;YACxC,IAAI,SAAS,CAAC,MAAM,KAAK,CAAC,EAAE;gBAC1B,QAAO,GAAG,CAAC,mLAAO,AAAP,EAAQ,IAAI,EAAE;oBAAC,CAAC;oBAAE,CAAC;oBAAE,SAAS,CAAC,CAAC,CAAC;iBAAC,CAAC,CAAC;aAChD,MAAM;gBACL,qLAAO,GAAG,CAAC,MAAA,AAAO,EAAC,IAAI,EAAE;oBAAC,CAAC;iBAAC,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC,CAAC;aACjD;SACF;KACF,MAAM,IAAI,KAAK,GAAG,CAAC,EAAE;QACpB,OAAO,IAAI,CAAC;KACb;IACD,MAAM,wKAAI,aAAU,CAAC,CAAA,mCAAA,EAAsC,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC;AAC1E,CAAC;AAYK,SAAU,OAAO,CACnB,CAAS,EAAE,IAAY,EAAE,UAAuB;IAClD,8KAAO,OAAA,AAAI,EAAC,GAAG,EAAE;QACf,IAAI,UAAU,IAAI,IAAI,EAAE;YACtB,UAAU,IAAG,oMAAA,AAAe,EAAE,CAAC;SAChC;gLACD,kBAAA,AAAe,EAAC,UAAU,CAAC,CAAC;QAE5B,iLAAO,GAAG,CAAC,EAAG,AAAH,EAAI,CAAC,EAAE,WAAW,CAAC,CAAC,CAAC,IAAI,EAAE,IAAI,EAAE,UAAU,CAAC,CAAC,CAAC;IAC3D,CAAC,CAAC,CAAC;AACL,CAAC;AAQK,SAAU,GAAG,CAAC,CAAS,EAAE,KAAK,GAAG,CAAC;IACtC,yDAAyD;IACzD,IAAI,KAAK,KAAK,CAAC,EAAE;QACf,MAAM,wKAAI,sBAAmB,CACzB,CAAA,uCAAA,EAA0C,KAAK,CAAA,qBAAA,CAAuB,GACtE,CAAA,IAAA,CAAM,CAAC,CAAC;KACb;IACD,iLAAO,GAAG,CAAC,EAAA,AAAG,EAAC,CAAC,CAAC,CAAC;AACpB,CAAC;AAUK,SAAU,QAAQ,CAAC,CAAS;IAChC,8KAAO,OAAA,AAAI,EAAC,GAAG,CAAG,CAAD,EAAI,CAAC,4KAAA,AAAG,EAAC,CAAC,4KAAE,GAAG,CAAC,EAAA,AAAG,4KAAC,GAAG,CAAC,EAAA,AAAG,EAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;AACxD,CAAC;AAYK,SAAU,OAAO,CACnB,CAAS,EAAE,KAAa,EAAE,UAAqB,EAAE,IAAa;IAChE,8KAAO,OAAA,AAAI,EAAC,GAAG,EAAE,AAAC,GAAG,CAAC,mLAAA,AAAO,EAAC,CAAC,EAAE,KAAK,EAAE,UAAU,EAAE,IAAI,CAAC,CAAC,CAAC;AAC7D,CAAC;AAWK,SAAU,WAAW,CAAC,CAAS;IACnC,8KAAO,OAAA,AAAI,EAAC,GAAG,EAAE;QACf,MAAM,CAAC,IAAG,GAAG,CAAC,2KAAA,AAAG,EAAC,EAAE,4KAAE,GAAG,CAAC,EAAG,AAAH,EAAI,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,2LAAO,GAAG,CAAC,UAAA,AAAW,EAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;IAClC,CAAC,CAAC,CAAC;AACL,CAAC;AAeK,SAAU,YAAY,CAAI,CAAU,EAAE,GAAY,EAAE,QAAQ,GAAG,KAAK;IACxE,OAAO,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,GAAG,EAAE,CAAC;AAChC,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 723, "column": 0}, "map": {"version":3,"file":"random_seed.js","sourceRoot":"","sources":["file:///project/sandbox/user-workspace/node_modules/%40tensorflow/tfjs-layers/dist/backend/random_seed.js/__/__/__/__/__/__/tfjs-layers/src/backend/random_seed.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2023 CodeSmith LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * Keeps track of seed and handles pseudorandomness\n * Instance created in BaseRandomLayer class\n * Utilized for random preprocessing layers\n */\n\nexport class RandomSeed {\n  static className = 'RandomSeed';\n  seed: number | undefined;\n  constructor(seed: number | undefined) { \n    this.seed = seed; \n  }\n  next(): number | undefined { \n    if (this.seed === undefined) {\n      return undefined;\n    }\n    return this.seed++; \n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;GAQG,CAEH;;;;GAIG;;;AAEH,MAAa,UAAU;IAGrB,YAAY,IAAwB,CAAA;QAClC,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC;IACnB,CAAC;IACD,IAAI,GAAA;QACF,IAAI,IAAI,CAAC,IAAI,KAAK,SAAS,EAAE;YAC3B,OAAO,SAAS,CAAC;SAClB;QACD,OAAO,IAAI,CAAC,IAAI,EAAE,CAAC;IACrB,CAAC;;AAVM,WAAA,SAAS,GAAG,YAAY,CAAC","ignoreList":[0],"debugId":null}}]
}